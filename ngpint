#! /usr/bin/env python3
#######################################################################################################
# Developed by: Sagnik Banerjee
# Version 1.7
# Modified to be used in conda environment
#
# Version: 1.6
# 
# This program will extract potential interactors of a certain Bait protein. Please
# launch python find_y2h_seq_candididates.py --help for more details of each possible functionality
# of the software. Please load the following modules before starting to run the program. Please note that 
# it is mandatory to preserve the sequence of the modules.
# 
# Updates from version 1.5
# Inclusion of logging system which logs information even with multiprocessing
#
# Updates from version 1.1:
# Now can process paired ended reads and leverage paired information during junction read detection
# 
# Updates from version 1.0:
# Only one csv file input is allowed
# STAR mappings to transcriptome is eliminated  
#    - Improves run time immensely
#    - No need to provide transcriptome index as input
#    - No need to provide gene annotations file as input (This will be generated by the pipeline)
#    - Users need to provide a GTF file though
# Option to generate transcript coverage graph is eliminated
# Fusion reads can now be viewed on IGV with vector sequence soft-clipped. From now on reads containing vector sequence will be referred to as Fusion reads consistently. 
# Produces much cleaner output and redirects all temporary files to another directory
# Fusion reads on IGV can now be viewed by grouping reads according to the tag "FR"
# Primer design is made easier with information available
# 
# BUG FIXES
# Version 1.5
# Trimming of reads have been modified - Each soft clipped read is checked for the presence of vector sequence for better fusion read recognition
# 
# Version 1.1
# Fixed a bug with reverse fusion read representation. The numbers in the header were incorrect. Now they have been corrected to represent the portion of the sequence that is NON-VECTOR
# Extracting the correct nucleotides after vector trimming. Previous version had one nucleotide off
# Fixed in-frame detection for cases where the mapping location was after the CDS end
# 
# TO DO
# Redesign the primer file. Output junction sequence for each transcript and each fragment. [Put in-frame junction reads in header]
#
# FEATURE ADDITION
# Version 1.4
#
# Add logging information through python logging module
# Version 1.5
# Better fusion read recognition
# No Logging
#
# Future Releases
#
# Incorporate Primer design softwares
# Restart computation from any point
# Impose memory restrictions
# Avoid recalculation in case of same background libraries
# Use pair information to prevent spurious hits for fusion reads
# Use modified model for enrichment analysis - both normalization and differential analysis
# Output HTML file for primer design
# Output complete sequences which were enriched 
#######################################################################################################
#######################################################################################################
"""# Defining the location of the executables
if sys.argv[0]!="find_y2h_seq_candidates_v1dot6.py":
    if platform.system()=="Linux":
        STAR="/".join(sys.argv[0].split("/")[:-1])+"/lib/star/Linux_x86_64/STAR "
    else:
        STAR="/".join(sys.argv[0].split("/")[:-1])+"/lib/star/MacOSX_x86_64/STAR "
    TRIMMOMATIC="/".join(sys.argv[0].split("/")[:-1])+"/lib/trimmomatic/trimmomatic-0.38.jar "
    SAMTOOLS="/".join(sys.argv[0].split("/")[:-1])+"/lib/samtools/samtools "
else:
    pass"""

from subprocess import *
import argparse
import collections
import datetime
import glob
import itertools
import math
import multiprocessing
import os
import pickle
import platform
import pprint
import re
import subprocess
import sys
import time

from ruffus.proxy_logger import *

from scripts.alignReadsWithSTAR import *
from scripts.detectTranscriptsWithSTOPCodonsIn5PrimeUTRSequence import *
from scripts.generateCounts import *
from scripts.generatePrimerDesign import *
from scripts.generateReports import *
from scripts.mapToTranscriptome import *
from scripts.purgeSequencesOffN import *
from scripts.readGeneInfo import *
from scripts.readWriteOperations import *
from scripts.reattachVectorPortions import *
from scripts.removeVectors import *
from scripts.trimOffAdapters import *


def parseCommandLineArguments():
    """
    Parses the arguments provided through command line.
    Launch python find_y2h_seq_candidates.py --help for more details
    """
    parser = argparse.ArgumentParser(prog="NGPINT.py",description="This pipeline can be used to find potential interactors of the bait. Please make sure that the following softwares are available in your path. We recommend that you trim adapters from your libraries and then supply them as selected and/or background files.")
    optional_arg = parser.add_argument_group("Optional Arguments")
    required_arg = parser.add_argument_group("Required Arguments")
    
    parser.add_argument("--all_arguments","-a",help="Enter the csv file which has all the information. No other argument is needed. Do NOT change the order in which the entries appear in this file. Do not add or remove any entry. For optional arguments the last column can be left blank.",default=None,required=True)
    parser.add_argument('--version', action='version', version='%(prog)s 1.0')
    # SUPRESSED ARGUMENTS
    parser.add_argument("--selected_filename",help=argparse.SUPPRESS) # Separates the name of the selected file from its path
    parser.add_argument("--selected_path",help=argparse.SUPPRESS) # Extracts the path of each selected file
    parser.add_argument("--selected_sample_adapter_trimmed",help=argparse.SUPPRESS) # Adapter trimmed Filename
    parser.add_argument("--selected_sample_adapter_trimmed_error_file",help=argparse.SUPPRESS) # Error file for adapter trimming
    parser.add_argument("--selected_sample_N_removed",help=argparse.SUPPRESS) # Name of each selected file with all non-ATGC nucleotides removed
    parser.add_argument("--selected_sample_STAR_prefix_round1",help=argparse.SUPPRESS) # In Round1 all reads will be mapped to detect fusion reads. This is just the prefix NOT the filename
    parser.add_argument("--selected_sample_STAR_round1_output",help=argparse.SUPPRESS)
    parser.add_argument("--selected_sample_STAR_round1_error",help=argparse.SUPPRESS)
    parser.add_argument("--selected_sample_STAR_genome_filename_round1",help=argparse.SUPPRESS) # Bamfilename of the genome mapped file
    parser.add_argument("--selected_sample_STAR_transcriptome_bamfilename_round1",help=argparse.SUPPRESS) # Bamfilename of the transcriptome mapped file
    parser.add_argument("--selected_sample_STAR_prefix_round2",help=argparse.SUPPRESS) # In Round2 fusion reads which were mapped to the vectors will be trimmed and mapped back
    parser.add_argument("--selected_sample_STAR_round2_output",help=argparse.SUPPRESS)
    parser.add_argument("--selected_sample_STAR_round2_error",help=argparse.SUPPRESS)
    parser.add_argument("--selected_sample_STAR_genome_filename_round2",help=argparse.SUPPRESS) # Bamfilename of the genome mapped file
    parser.add_argument("--selected_sample_STAR_transcriptome_bamfilename_round2",help=argparse.SUPPRESS) # Bamfilename of the transcriptome mapped file
    parser.add_argument("--selected_sample_STAR_transcriptome_bamfilename_round2_fusion_reads",help=argparse.SUPPRESS) # Bamfilename of the transcriptome mapped file containing only fusion reads
    parser.add_argument("--selected_sample_trimming_stats",help=argparse.SUPPRESS) # Contains information related to vector trimming like number of reads trimmed etc.
    parser.add_argument("--selected_sample_all_reads_vector_trimmed",help=argparse.SUPPRESS) # Contains all the reads including vector trimmed ones and reads which do not contain any vector sequence
    parser.add_argument("--selected_sample_fusion_reads",help=argparse.SUPPRESS) # Contains only the fusion reads
    parser.add_argument("--selected_sample_genome_browser",help=argparse.SUPPRESS) # Samfilename for all reads to be viewed in Genome Browser
    parser.add_argument("--selected_sample_genome_browser_per_replicate",help=argparse.SUPPRESS) # Samfilename for all reads to be viewed in Genome Browser per replicate
    parser.add_argument("--selected_sample_salmon_counts_outputfile",help=argparse.SUPPRESS) # Counts file for salmon counts
    parser.add_argument("--selected_sample_salmon_counts_error",help=argparse.SUPPRESS) # Error file for salmon counts
    parser.add_argument("--selected_sample_transcriptome_coverage_bed_all_reads",help=argparse.SUPPRESS) # Bed file to store the mappings counts for each transcript
    parser.add_argument("--selected_sample_transcriptome_coverage_bed_fusion_reads",help=argparse.SUPPRESS)
    parser.add_argument("--selected_sample_transcriptome_coverage_bed_all_reads_splits",help=argparse.SUPPRESS) # Bed file to store the mappings counts for each transcript
    parser.add_argument("--selected_sample_transcriptome_coverage_bed_fusion_reads_splits",help=argparse.SUPPRESS) 
    parser.add_argument("--selected_sample_idxstats_filename_all_reads",help=argparse.SUPPRESS) # Idxstats file for storing number of reads mapped to a transcript
    parser.add_argument("--selected_sample_idxstats_filename_fusion_reads",help=argparse.SUPPRESS) # Idxstats file for storing number of fusion reads mapped to a transcript
    parser.add_argument("--selected_sample_graph_info_filename",help=argparse.SUPPRESS) # Information about graphs
    parser.add_argument("--selected_sample_for_cross_library_analysis",help=argparse.SUPPRESS) # selected_sample_for_cross_library_analysis
    parser.add_argument("--selected_sample_amplicon_filename",help=argparse.SUPPRESS)
    parser.add_argument("--selected_sample_transcript_read_coverage",help=argparse.SUPPRESS)
    parser.add_argument("--selected_sample_per_read_log",help=argparse.SUPPRESS)# Log to describe each read
    
    parser.add_argument("--background_sample",help=argparse.SUPPRESS) # Separates the name of the selected file from its path
    parser.add_argument("--background_path",help=argparse.SUPPRESS) # Extracts the path of each selected file
    parser.add_argument("--background_sample_adapter_trimmed",help=argparse.SUPPRESS) # Adapter trimmed Filename
    parser.add_argument("--background_sample_adapter_trimmed_error_file",help=argparse.SUPPRESS) # Error file for adapter trimming
    parser.add_argument("--background_sample_N_removed",help=argparse.SUPPRESS) # Name of each selected file with all non-ATGC nucleotides removed
    parser.add_argument("--background_sample_STAR_prefix_round1",help=argparse.SUPPRESS) # In Round1 all reads will be mapped to detect fusion reads. This is just the prefix NOT the filename
    parser.add_argument("--background_sample_STAR_round1_output",help=argparse.SUPPRESS)
    parser.add_argument("--background_sample_STAR_round1_error",help=argparse.SUPPRESS)
    parser.add_argument("--background_sample_STAR_genome_bamfilename_round1",help=argparse.SUPPRESS) # Bamfilename of the genome mapped file
    parser.add_argument("--background_sample_STAR_genome_filename_round1",help=argparse.SUPPRESS) # Bamfilename of the transcriptome mapped file
    parser.add_argument("--background_sample_STAR_prefix_round2",help=argparse.SUPPRESS) # In Round2 fusion reads which were mapped to the vectors will be trimmed and mapped back
    parser.add_argument("--background_sample_STAR_round2_output",help=argparse.SUPPRESS)
    parser.add_argument("--background_sample_STAR_round2_error",help=argparse.SUPPRESS)
    parser.add_argument("--background_sample_STAR_genome_filename_round2",help=argparse.SUPPRESS) # Bamfilename of the genome mapped file
    parser.add_argument("--background_sample_STAR_transcriptome_bamfilename_round2",help=argparse.SUPPRESS) # Bamfilename of the transcriptome mapped file
    parser.add_argument("--background_sample_STAR_transcriptome_bamfilename_round2_fusion_reads",help=argparse.SUPPRESS) # Bamfilename of the transcriptome mapped file containing only fusion reads
    parser.add_argument("--background_sample_trimming_stats",help=argparse.SUPPRESS) # Contains information related to vector trimming like number of reads trimmed etc.
    parser.add_argument("--background_sample_all_reads_vector_trimmed",help=argparse.SUPPRESS) # Contains all the reads including vector trimmed ones and reads which do not contain any vector sequence
    parser.add_argument("--background_sample_fusion_reads",help=argparse.SUPPRESS) # Contains only the fusion reads
    parser.add_argument("--background_sample_salmon_counts_outputfile",help=argparse.SUPPRESS) # Counts file for salmon counts
    parser.add_argument("--background_sample_salmon_counts_error",help=argparse.SUPPRESS) # Error file for salmon counts
    parser.add_argument("--background_sample_per_read_log",help=argparse.SUPPRESS)# Log to describe each read
    
    parser.add_argument("--temp_output_directory",help=argparse.SUPPRESS)
    parser.add_argument("--transcript_to_gene_map",help=argparse.SUPPRESS)
    parser.add_argument("--transcriptome",help=argparse.SUPPRESS) # Name of the transcriptome file generated by gffread
    parser.add_argument("--transcriptome_index",help=argparse.SUPPRESS) # STAR index of the transcriptome
    parser.add_argument("--salmon_normalized_counts",help=argparse.SUPPRESS)
    parser.add_argument("--salmon_DGE_filename",help=argparse.SUPPRESS)
    parser.add_argument("--salmon_gene_counts_matrix",help=argparse.SUPPRESS) # Combined file containing all the count data
    parser.add_argument("--deseq2_normalized_counts",help=argparse.SUPPRESS) # File containing normalized values
    parser.add_argument("--deseq2_DGE_output",help=argparse.SUPPRESS) # Output file from DESeq2
    parser.add_argument("--os",help=argparse.SUPPRESS)
    parser.add_argument("--combined_graph_final",help=argparse.SUPPRESS) # Contains all the information about each enrichment of genes in each of the replicates
    parser.add_argument("--run_details_info_csv",help=argparse.SUPPRESS) # Holds information about the runtime of each of the steps and other relevant information 
    parser.add_argument("--record_time",help=argparse.SUPPRESS)# Holds duration of execution for each step of execution
    parser.add_argument("--design_primers_for_transcript",help=argparse.SUPPRESS)# The filename where all transcripts are displayed with in-frame junction information required for primer design
    
    return parser.parse_args()

def populateOptionsDataStructure(options,filename):
    """
    Populates the options with data provided by the use
    """
    whole_data=[line.strip().split(",") for line in open(filename,"r",encoding="ISO-8859-1").read().split("\n")[1:]]
    """for line in whole_data:
        print(line)"""
    #print(whole_data[4])
    options.selected_ended=whole_data[0][3] if whole_data[0][4]=="" else whole_data[0][4] 
    #options.selected_fullpath=[file.strip("\"") for file in whole_data[1][4:].split(";")]
    options.selected_fullpath=whole_data[1][4].split(";")
    options.background_ended=whole_data[2][3] if whole_data[2][4]=="" else whole_data[2][4]
    #options.background_fullpath=[file.strip("\"") for file in whole_data[3][4:].split(";")]
    options.background_fullpath=whole_data[3][4].split(";")
    options.genome=whole_data[4][4]
    options.star_genome_index=whole_data[5][4] if whole_data[5][4]!="" else None  
    options.output_directory=whole_data[6][4] 
    options.plasmid_sequences=whole_data[7][4]
    options.five_prime_vector=whole_data[8][4]
    options.three_prime_vector=whole_data[9][4]
    options.CPU=int(whole_data[10][4]) if whole_data[10][4]!="" else whole_data[10][3]  
    options.frame_of_TF_fusion=whole_data[11][4] if whole_data[11][4]!="" else whole_data[11][3] 
    options.nucleotide_for_frame_shift=whole_data[12][4] if whole_data[12][4]!="" else whole_data[12][3] 
    options.min_trimmed_length=whole_data[13][4] if whole_data[13][4]!="" else whole_data[13][3]
    options.min_trimmed_length=int(options.min_trimmed_length) 
    options.force=whole_data[14][4] if whole_data[14][4]!="" else whole_data[14][3] 
    options.clean_up=whole_data[15][4] if whole_data[15][4]!="" else whole_data[15][3]
    options.gtf=whole_data[16][4] 
    options.functional_annotation=whole_data[17][4]
    options.transcriptome_index=whole_data[18][4]
    return options

def analyzeCommandLineArguments(options,logger_proxy,logging_mutex):
    """
    Performs checks on the validity of the arguments provided 
    through the command line.
    """
    """for key in vars(options):
        if vars(options)[key] is not None:
            print(key,vars(options)[key])"""
    
    flag=0
    if platform.system()=="Linux":
        options.os="linux"
    elif platform.system()=="Darwin":
        options.os="mac"
    else:
        options.os="Invalid"
        os.system("echo \" You need Linux or Mac to execute the software\"")
        flag=1
        
    if options.selected_ended==options.background_ended:
        if len(options.selected_fullpath)!=len(options.background_fullpath):
            with logging_mutex:
                logger_proxy.info("You must have equal number of selected and non-selected libraries. EXECUTION STOPPED")
            #logger.error("You must have equal number of selected and non-selected libraries. EXECUTION STOPPED")
            flag=1
    else:
        if options.selected_ended=="SE" and options.background_ended=="PE" and len(options.selected_fullpath)*2!=len(options.background_fullpath):
            #logger.error("For every selected sample you must have 2 non-selected samples. EXECUTION STOPPED")
            with logging_mutex:
                logger_proxy.info("For every selected sample you must have 2 non-selected samples. EXECUTION STOPPED")
            flag=1
        if options.selected_ended=="PE" and options.background_ended=="SE" and len(options.selected_fullpath)!=2*len(options.background_fullpath):
            #logger.error("For every non-selected sample you must have 2 selected samples. EXECUTION STOPPED")
            with logging_mutex:
                logger_proxy.info("For every non-selected sample you must have 2 selected samples. EXECUTION STOPPED")
            flag=1
    
    if os.path.exists(options.genome)==False:
        #logger.error("The genome file you provided does not exist. EXECUTION STOPPED")
        with logging_mutex:
            logger_proxy.info("The genome file you provided does not exist. EXECUTION STOPPED "+options.genome)
        flag=1
        
    for filename in options.selected_fullpath:
        if os.path.exists(filename)==False:
            #logger.error("The selected file "+filename+" does not exist. EXECUTION STOPPED")
            with logging_mutex:
                logger_proxy.info("The selected file "+filename+" does not exist. EXECUTION STOPPED")
            flag=1
    
    for filename in options.background_fullpath:
        if os.path.exists(filename)==False:
            #logger.error("The background file "+filename+" does not exist. EXECUTION STOPPED")
            with logging_mutex:
                logger_proxy.info("The background file "+filename+" does not exist. EXECUTION STOPPED")
            flag=1
    
    options.temp_output_directory=options.output_directory+"/temp"
    os.system("mkdir -p "+options.temp_output_directory)
    fhw=open(options.temp_output_directory+"/vector_sequences.fasta","w")
    fhw.write(">5_prime_end\n"+options.five_prime_vector+"\n>3_prime_end\n"+options.three_prime_vector+"\n")
    fhw.close()
    options.vector_sequences=options.temp_output_directory+"/vector_sequences.fasta"
    
    if flag==1:
        print("The program had to terminate prematurely....Please check "+options.output_directory+"/progress.log file for more details")
        sys.stdout.flush()
        sys.exit()
        
    if options.star_genome_index is None or options.star_genome_index=="":
        os.system("rm -rf "+options.temp_output_directory+"/star_index_with_vectors_with_transcriptome.temp")
        
        cmd="mkdir -p "+options.temp_output_directory+"/star_index_with_vectors_with_transcriptome"
        os.system(cmd)
        
        cmd="STAR "
        cmd+=" --runThreadN "+str(options.CPU)
        cmd+=" --runMode genomeGenerate "
        cmd+=" --genomeDir "+options.temp_output_directory+"/star_index_with_vectors_with_transcriptome"
        cmd+=" --genomeFastaFiles "+options.genome+" "+options.plasmid_sequences+" "+options.vector_sequences
        cmd+=" --sjdbGTFfile "+options.gtf
        cmd+=" --outTmpDir "+options.temp_output_directory+"/star_index_with_vectors_with_transcriptome.temp "
        cmd+=" > "+options.temp_output_directory+"/star_index_with_vectors_with_transcriptome.output"
        cmd+=" 2> "+options.temp_output_directory+"/star_index_with_vectors_with_transcriptome.error"
        os.system(cmd)
        
        options.star_genome_index=options.temp_output_directory+"/star_index_with_vectors_with_transcriptome"
        with logging_mutex:
            logger_proxy.info("STAR index generation complete")
        """cmd="cat "+options.temp_output_directory+"/star_index_with_vectors_with_transcriptome.error >> "+options.output_directory+"/progress.log"
        os.system(cmd)"""
    
    
    options.transcriptome=options.temp_output_directory+"/transcriptome.fasta"
    cmd="gffread "+options.gtf+" -g "+options.genome+" -w "+options.transcriptome
    os.system(cmd)
    
    cmd="perl -pe '/^>/ ? print \"\n\" : chomp' "+options.transcriptome+"|tail -n +2 > "+options.transcriptome+".temp"
    os.system(cmd)
    
    cmd="mv "+options.transcriptome+".temp "+options.transcriptome
    os.system(cmd)
    
    # Creating STAR index for the transcriptome
    if options.transcriptome_index is None or options.transcriptome_index=="":
        os.system("mkdir -p "+options.temp_output_directory+"/star_index_transcriptome")
        
        os.system("rm -rf "+options.temp_output_directory+"/star_index_transcriptome.temp ")
        cmd="STAR "
        cmd+=" --runThreadN "+str(options.CPU)
        cmd+=" --runMode genomeGenerate "
        cmd+=" --genomeDir "+options.temp_output_directory+"/star_index_transcriptome "
        cmd+=" --genomeFastaFiles "+options.transcriptome
        cmd+=" --limitGenomeGenerateRAM 63689134805 "
        cmd+=" --outTmpDir "+options.temp_output_directory+"/star_index_transcriptome.temp "
        cmd+=" > "+options.temp_output_directory+"/star_index_transcriptome.output "
        cmd+=" 2> "+options.temp_output_directory+"/star_index_transcriptome.error "
        os.system(cmd)
        options.transcriptome_index=options.temp_output_directory+"/star_index_transcriptome"
    
    options.transcript_to_gene_map=options.temp_output_directory+"/transcript_to_gene_map"
    # Defining the SUPPRESSED arguments
    options.selected_path=[]
    for selected_lib_path in options.selected_fullpath:
        options.selected_path.append("/".join(selected_lib_path.split("/")[:-1]))
    options.selected_sample=[]
    for filenames in options.selected_fullpath:
        options.selected_sample.append(filenames.split("/")[-1].split(".")[0])
        
    options.background_path=[]
    for background_lib_path in options.background_fullpath:
        options.background_path.append("/".join(background_lib_path.split("/")[:-1]))
    options.background_sample=[]
    for filename in options.background_fullpath:
        options.background_sample.append(filename.split("/")[-1].split(".")[0])
    
    if os.path.exists(options.genome+".fai")==False:
        cmd="samtools faidx "+options.genome
        os.system(cmd)
    
    options.selected_sample_adapter_trimmed=[]
    options.selected_sample_adapter_trimmed_error_file=[]
    options.selected_sample_N_removed=[]
    options.selected_sample_STAR_prefix_round1=[]
    options.selected_sample_STAR_round1_output=[]
    options.selected_sample_STAR_round1_error=[]
    options.selected_sample_STAR_genome_filename_round1=[]
    options.selected_sample_STAR_transcriptome_bamfilename_round1=[]
    options.selected_sample_STAR_prefix_round2=[]
    options.selected_sample_STAR_round2_output=[]
    options.selected_sample_STAR_round2_error=[]
    options.selected_sample_STAR_genome_filename_round2=[]
    options.selected_sample_STAR_transcriptome_bamfilename_round2=[]
    options.selected_sample_STAR_transcriptome_bamfilename_round2_fusion_reads=[]
    options.selected_sample_trimming_stats=[]
    options.selected_sample_all_reads_vector_trimmed=[]
    options.selected_sample_fusion_reads=[]
    options.selected_sample_salmon_counts_outputfile=[]
    options.selected_sample_salmon_counts_error=[]
    options.selected_sample_transcriptome_coverage_bed_all_reads=[]
    options.selected_sample_transcriptome_coverage_bed_fusion_reads=[]
    options.selected_sample_idxstats_filename_all_reads=[]
    options.selected_sample_idxstats_filename_fusion_reads=[]
    options.selected_sample_transcript_read_coverage=[]
    options.selected_sample_graph_info_filename=[]
    options.selected_sample_for_cross_library_analysis=[]
    options.selected_sample_amplicon_filename=[]
    options.selected_sample_genome_browser_per_replicate=[]
    options.selected_filename=options.selected_sample
    options.selected_sample_per_read_log=[]
    for filename in options.selected_sample:
        options.selected_sample_adapter_trimmed.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_adapter_trimmed.fastq")
        options.selected_sample_adapter_trimmed_error_file.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_adapter_trimmed.error")
        options.selected_sample_N_removed.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_N_removed.fastq")
        options.selected_sample_STAR_prefix_round1.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1_")
        options.selected_sample_STAR_round1_output.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1.output")
        options.selected_sample_STAR_round1_error.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1.error")
        options.selected_sample_STAR_genome_filename_round1.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1_Aligned.out.sam")
        options.selected_sample_STAR_transcriptome_bamfilename_round1.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1_Aligned.toTranscriptome.out.bam")
        options.selected_sample_STAR_prefix_round2.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2_")
        options.selected_sample_STAR_round2_output.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2.output")
        options.selected_sample_STAR_round2_error.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2.error")
        options.selected_sample_STAR_genome_filename_round2.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2_Aligned.out.sam")
        options.selected_sample_STAR_transcriptome_bamfilename_round2.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2_Aligned.toTranscriptome.out.bam")
        options.selected_sample_STAR_transcriptome_bamfilename_round2_fusion_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2_fusion_reads_Aligned.toTranscriptome.out.bam")
        options.selected_sample_trimming_stats.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_trim.stats")
        options.selected_sample_all_reads_vector_trimmed.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_trimmed_reads.fastq")
        options.selected_sample_fusion_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_fusion_reads.fastq")
        options.selected_sample_salmon_counts_error.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_salmon.error")
        options.selected_sample_salmon_counts_outputfile.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_salmon_counts")
        options.selected_sample_transcriptome_coverage_bed_all_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_forGraphs_trimmed_reads.bed")
        options.selected_sample_transcriptome_coverage_bed_fusion_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_forGraphs_fusion_reads.bed")
        options.selected_sample_idxstats_filename_all_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_transcriptome_Aligned.out.sorted.idxstats")
        options.selected_sample_idxstats_filename_fusion_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_transcriptome_fusion_reads_Aligned.out.sorted.idxstats")
        options.selected_sample_transcript_read_coverage.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_transcript_read_coverage.txt") # Filename to store the selected transcripts based on the number of reads that are mapped to that transcript
        options.selected_sample_graph_info_filename.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_graphs.tab")
        options.selected_sample_for_cross_library_analysis.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_for_cross_library_analysis.csv")
        options.selected_sample_amplicon_filename.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_full_length_amplicons_with_vectors.fasta")
        options.selected_sample_genome_browser_per_replicate.append(options.output_directory+"/"+filename.split(".fastq")[0]+"_genome_browser.bam")
        options.selected_sample_per_read_log.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_fusion_read_info.log")
        
    options.background_sample_adapter_trimmed=[]
    options.background_sample_adapter_trimmed_error_file=[]
    options.background_sample_N_removed=[]
    options.background_sample_STAR_prefix_round1=[]
    options.background_sample_STAR_round1_output=[]
    options.background_sample_STAR_round1_error=[]
    options.background_sample_STAR_genome_filename_round1=[]
    options.background_sample_STAR_transcriptome_bamfilename_round1=[]
    options.background_sample_STAR_prefix_round2=[]
    options.background_sample_STAR_round2_output=[]
    options.background_sample_STAR_round2_error=[]
    options.background_sample_STAR_genome_filename_round2=[]
    options.background_sample_STAR_transcriptome_bamfilename_round2=[]
    options.background_sample_trimming_stats=[]
    options.background_sample_all_reads_vector_trimmed=[]
    options.background_sample_fusion_reads=[]
    options.background_sample_salmon_counts_outputfile=[]
    options.background_sample_salmon_counts_error=[]
    options.background_sample_transcriptome_coverage_bed_all_reads=[]
    options.background_sample_transcriptome_coverage_bed_fusion_reads=[]
    options.background_sample_STAR_transcriptome_bamfilename_round2_fusion_reads=[]
    options.background_sample=options.background_sample
    options.background_sample_per_read_log=[]

    for filename in options.background_sample:
        options.background_sample_adapter_trimmed.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_adapter_trimmed.fastq")
        options.background_sample_adapter_trimmed_error_file.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_adapter_trimmed.error")
        options.background_sample_N_removed.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_N_removed.fastq")
        options.background_sample_STAR_prefix_round1.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1_")
        options.background_sample_STAR_round1_output.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1.output")
        options.background_sample_STAR_round1_error.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1.error")
        options.background_sample_STAR_genome_filename_round1.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1_Aligned.out.sam")
        options.background_sample_STAR_transcriptome_bamfilename_round1.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round1_Aligned.toTranscriptome.out.bam")
        options.background_sample_STAR_prefix_round2.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2_")
        options.background_sample_STAR_round2_output.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2.output")
        options.background_sample_STAR_round2_error.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2.error")
        options.background_sample_STAR_genome_filename_round2.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2_Aligned.out.sam")
        options.background_sample_STAR_transcriptome_bamfilename_round2.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2_Aligned.toTranscriptome.out.bam")
        options.background_sample_trimming_stats.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_trim.stats")
        options.background_sample_all_reads_vector_trimmed.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_trimmed_reads.fastq")
        options.background_sample_fusion_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_fusion_reads.fastq")
        options.background_sample_salmon_counts_error.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_salmon.error")
        options.background_sample_salmon_counts_outputfile.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_salmon_counts")
        options.background_sample_transcriptome_coverage_bed_all_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_forGraphs_trimmed_reads.bed")
        options.background_sample_transcriptome_coverage_bed_fusion_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_forGraphs_fusion_reads.bed")
        options.background_sample_STAR_transcriptome_bamfilename_round2_fusion_reads.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_STAR_round2_fusion_reads_Aligned.toTranscriptome.out.bam")
        options.background_sample_per_read_log.append(options.temp_output_directory+"/"+filename.split(".fastq")[0]+"_fusion_read_info.log")
        
    options.selected_sample_genome_browser=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_genome_browser.bam"
    options.combined_graph_temp=options.output_directory+"/"+options.temp_output_directory.split("/")[-1]+"_combined_graphs_temp.tab"
    options.combined_graph_final=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_final_report.csv"
    options.combined_graph=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_combined_graphs.tab"
    options.salmon_normalized_counts=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_salmon_counts.matrix_norm.csv"
    options.salmon_DGE_filename=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_salmon_counts.matrix_DGE_Indept_filtering_Off_Cooks_Off.csv"
    
    options.salmon_gene_counts_matrix=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_salmon_counts.matrix"
    options.deseq2_DGE_output=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_salmon_counts.matrix_DGE_Indept_filtering_On_Cooks_On.csv"
    options.deseq2_normalized_counts=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_salmon_counts.matrix_norm.csv"
    options.run_details_info_csv=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_run_details.csv"
    options.frame_of_TF_fusion=int(options.frame_of_TF_fusion)
    options.record_time={}
    options.design_primers_for_transcript=options.output_directory+"/"+options.output_directory.split("/")[-1]+"_transcriptome_file_for_primer_design.txt"
    
    return options    

def convertToDateAndTime(seconds):
    """
    Returns a string with hours, minutes and seconds
    """
    hours=seconds//3600
    minutes=(seconds%3600)//60
    seconds=(seconds%60)
    return str(hours)+" hrs, "+str(minutes)+" min, "+str(seconds)+" seconds"

def generateTranscriptToGeneMap(gtffilename,options):
    """
    """
    cmd="paste <(cat "+gtffilename+" |rev|cut -f1|rev|cut -d\" \" -f2|cut -c2-|rev|cut -c3-|rev) "
    cmd+="<(cat "+gtffilename+" |rev|cut -f1|rev|cut -d\" \" -f4|cut -c2-|rev|cut -c3-|rev)|sort|uniq "
    cmd+=" > "+options.transcript_to_gene_map
    subprocess.check_call(['bash', '-c', cmd])
 
def removeRedundantMappingsInParallel(inputs):
    """
    - Removes mappings which maps to both vector and genome
    - Preserves the match which is to the vector and discard the rest
    """
    samfile,options=inputs
    # Select those reads which have at least one mapping to the vectors
    cmd="grep prime_end "+samfile+"|grep -v ^\"@\" | cut -f1 | uniq > "+samfile+".reads_mapped_to_vectors"
    #print(cmd)
    os.system(cmd)
    reads_mapped_to_vectors=set(open(samfile+".reads_mapped_to_vectors","r").read().split("\n"))
    #print(len(reads_mapped_to_vectors),"reads mapped to vectors")
    cmd="rm "+samfile+".reads_mapped_to_vectors"
    os.system(cmd)
    
    # Select the correct mappings
    output=samfile+".temp"
    fhw=open(output,"w")
    fhr=open(samfile,"r")
    for line in fhr:
        if "@"==line[0]:
            fhw.write(line)
            continue
        read_id,flag,chromosome=line.split()[0],line.split()[1],line.split()[2]
        if read_id in reads_mapped_to_vectors:
            if "prime" in chromosome:
                fhw.write(line)
        else:
            if flag!="4":
                fhw.write(line)
    fhw.close()
    fhr.close()
    cmd="mv "+output+" "+samfile
    os.system(cmd)
    
def removeRedundantMappings(options):
    """
    - Runs the removeRedundantMappingsInParallel function for all the samfiles
    """
    pool = multiprocessing.Pool(processes=int(options.CPU))
    allinputs=[]
    
    for num,eachtype in enumerate([options.selected_sample,options.background_sample]):
        for file_num,filename in enumerate(eachtype):
            if num==0:
                inputfilename=options.selected_sample_STAR_genome_filename_round1[file_num]
                #inputfilename=options.selected_sample_STAR_prefix_for_vector_trimming[file_num]+"Aligned.out.sam"
            else:
                inputfilename=options.background_sample_STAR_genome_filename_round1[file_num]
                #inputfilename=options.background_sample_STAR_prefix_for_vector_trimming[file_num]+"Aligned.out.sam"
            allinputs.append([inputfilename,options])
    pool.map(removeRedundantMappingsInParallel,allinputs)

def attempToFindMatches(vector_seq,read_seq,length):
    """
    """
    i=0
    all_hamming_distances=[]
    while i<len(read_seq)-length:
        if hamming_distance(read_seq[i:i+length],vector_seq)!=0:
            all_hamming_distances.append(hamming_distance(read_seq[i:i+length],vector_seq))
        else:
            #print(vector_seq,read_seq[i:i+length])
            #sys.stdout.flush()
            return i,0
        i+=1
    #print(vector_seq,read_seq[all_hamming_distances.index(min(all_hamming_distances)):all_hamming_distances.index(min(all_hamming_distances))+length])
    if min(all_hamming_distances)>2:return -1,-1
    return all_hamming_distances.index(min(all_hamming_distances)),min(all_hamming_distances)

def rev_comp(seq):
    """
    """
    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}
    return "".join(complement[base] for base in seq)[::-1]

def checkForThreePrimeVectorEndClipped(read_seq,three_prime_vector,extract_from,options):
    """
    hamming_distance(read_seq[-extract_from:],vectors["3_prime_end"][:extract_from])
    """
    # Check for overlap matches
    #sequences_to_be_checked=[]
    all_hamming_distances=[]
    i=extract_from
    while i>=int(options.min_trimmed_length):
        #sequences_to_be_checked.append([read_seq[-i:],three_prime_vector[:i]])
        all_hamming_distances.append(hamming_distance(read_seq[-i:],three_prime_vector[:i] ))
        all_hamming_distances.append(hamming_distance(read_seq[-i:],reverseComplement(three_prime_vector[:i]) ))
        i-=1
    return min(all_hamming_distances),all_hamming_distances.index(min(all_hamming_distances))%2

def checkForThreePrimeVectorFrontClipped(read_seq,three_prime_vector,extract_till,options):
    """
    hamming_distance(read_seq[-extract_from:],vectors["3_prime_end"][:extract_from])
    """
    # Check for overlap matches
    #sequences_to_be_checked=[]
    all_hamming_distances=[]
    i=extract_till
    while i>=int(options.min_trimmed_length):
        #sequences_to_be_checked.append([read_seq[-i:],three_prime_vector[:i]])
        all_hamming_distances.append(hamming_distance(read_seq[:i],three_prime_vector[:i] ))
        all_hamming_distances.append(hamming_distance(read_seq[:i],reverseComplement(three_prime_vector[:i]) ))
        i-=1
    return min(all_hamming_distances),all_hamming_distances.index(min(all_hamming_distances))%2
                    
def performEnrichmentAnalysis(options):
    """
    Calls the R program to output DGE list of genes
    """
    if options.selected_ended=="SE" and options.background_ended=="SE":
        cmd="perform_DE_analysis_deseq2.R "
        cmd+=options.output_directory+" "
        cmd+=options.salmon_gene_counts_matrix.split("/")[-1]
        cmd+=" "+str(0.05)+" "
        cmd+=" ".join(options.selected_sample)+" "
        cmd+=" ".join(options.background_sample)+" "
        cmd+=" > "+options.output_directory+"/deseq2.output "
        cmd+=" 2> "+options.output_directory+"/deseq2.error "
        os.system(cmd)
    else:
        cmd="perform_DE_analysis_deseq2.R "
        cmd+=options.output_directory+" "
        cmd+=options.salmon_gene_counts_matrix.split("/")[-1]
        cmd+=" "+str(0.05)+" "
        cmd+=" ".join(options.selected_sample[0:len(options.selected_sample):2])+" "
        cmd+=" ".join(options.background_sample[0:len(options.background_sample):2])+" "
        cmd+=" > "+options.output_directory+"/deseq2.output "
        cmd+=" 2> "+options.output_directory+"/deseq2.error "
        os.system(cmd)
    print(cmd)

def createJunctionFileForBackgroundLibraries(inputs):
    inputfilename,outputfilename=inputs
    samoutputfilename=outputfilename[:-3]+"sam"
    cmd="samtools view -H "+inputfilename+" > "+samoutputfilename
    os.system(cmd)
    cmd="samtools view "+inputfilename+"|grep prime >> "+samoutputfilename
    os.system(cmd)
    cmd="samtools view -Sb -o "+outputfilename+" "+samoutputfilename
    os.system(cmd)

def calculate_in_frame_score(transcript_id,selected_sample_filename,num_reads_in_frame_s,num_reads_out_of_frame_s,num_reads_in_frame_ns,num_reads_out_of_frame_ns):
    """
    """
    
    """
    calculate_score <- function(count_table, alpha=0.05){
    data <- count_table
    data$in_frame_prop_s <- data$num_junction_reads_in_frame_s/data$num_junction_reads_s
    data$in_frame_prop_ns <- data$num_junction_reads_in_frame_ns/data$num_junction_reads_ns
    
    #with normal
    #If we have data from NS libraries
    data$in_frame_prop_ns_ho<- data$in_frame_prop_ns
    data$in_frame_prop_ns_ho[data$num_junction_reads_ns==0]<- 1/3
    data$statistic<- (data$in_frame_prop_s-data$in_frame_prop_ns_ho)/
      sqrt((data$in_frame_prop_s*(1-data$in_frame_prop_s))/(data$num_junction_reads_s+1)+
             (data$in_frame_prop_ns_ho*(1-data$in_frame_prop_ns_ho))/(data$num_junction_reads_ns+1))
    
    data$p_val <- pnorm(q=data$statistic,lower.tail = FALSE)
    data$rank <- rank(data$statistic)
    data$freq_score <- data$rank/max(data$rank)
    #data$freq_score <- pnorm(q=data$statistic) #1-data$p_val
    
    data[is.na(data$freq_score),"freq_score"] <- 0
    return(data)
    """
    if num_reads_in_frame_s<0:num_reads_in_frame_s=0
    if num_reads_out_of_frame_s<0:num_reads_out_of_frame_s=0
    if num_reads_in_frame_ns<0:num_reads_in_frame_ns=0
    if num_reads_out_of_frame_ns<0:num_reads_out_of_frame_ns=0
    
    num_junction_reads_s=num_reads_in_frame_s+num_reads_out_of_frame_s
    num_junction_reads_ns=num_reads_in_frame_ns+num_reads_out_of_frame_ns
    in_frame_proportion_s=num_reads_in_frame_s/num_junction_reads_s
    in_frame_proportion_ns=num_reads_in_frame_ns/num_junction_reads_ns
    
    if in_frame_proportion_ns==0:
        in_frame_proportion_ns=1/3
        
    test_statistic_numerator=in_frame_proportion_s-in_frame_proportion_ns
    test_statistic_denominator_part1=in_frame_proportion_s*(1-in_frame_proportion_s)/(num_junction_reads_s+1)
    test_statistic_denominator_part2=in_frame_proportion_ns*(1-in_frame_proportion_ns)/(num_junction_reads_ns+1)
    print(num_reads_in_frame_s,num_reads_out_of_frame_s,num_reads_in_frame_ns,num_reads_out_of_frame_ns)
    print(transcript_id,selected_sample_filename,test_statistic_numerator,test_statistic_denominator_part1,test_statistic_denominator_part2)
    sys.stdout.flush()
    test_statistic=test_statistic_numerator/math.sqrt(test_statistic_denominator_part1 + test_statistic_denominator_part2)
    
    #print(transcript_id,selected_sample_filename,stats.norm.ppf(test_statistic))
    sys.stdout.flush()

def configureLogger(options):
    """
    """
    os.system("mkdir -p "+options.output_directory)
    os.system("rm "+options.output_directory+"/progress.log")
    
    arguments={}
    arguments["file_name"]=options.output_directory+"/progress.log"
    arguments["formatter"] = "%(asctime)s - %(name)s - %(levelname)6s - %(message)s"
    arguments["level"]     = logging.DEBUG
    arguments["delay"]     = False
    
    (logger_proxy,logging_mutex) = make_shared_logger_and_proxy (setup_std_shared_logger,"PRIDE", arguments)
    
    return logger_proxy,logging_mutex

def main():
    commandLineArg=sys.argv
    if len(commandLineArg)==1:
        print("Please use the --help option to get usage information")
    
    current_time=time.time()
    options=parseCommandLineArguments()
    options=populateOptionsDataStructure(options,options.all_arguments)
    logger_proxy,logging_mutex=configureLogger(options)
    
    options=analyzeCommandLineArguments(options,logger_proxy,logging_mutex)
    options.record_time["analyzeCommandLineArguments"]=str(convertToDateAndTime(int(time.time()-current_time)))
    
    current_time=time.time()
    generateTranscriptToGeneMap(options.gtf,options)
    options.record_time["generateTranscriptToGeneMap"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Transcripts mapped to Genes")
    
    
    current_time=time.time()
    gene_info=getGeneInfo(options.transcriptome,options.transcript_to_gene_map)
    options.record_time["getGeneInfo"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Gene info extracted")
    
    
    current_time=time.time()
    transcripts_to_in_frame_STOP_codon_locations_in_5_prime_UTR_region=findTranscriptsWithSTOPCodonsIn5PrimeUTRSequence(options,gene_info)
    options.record_time["findTranscriptsWithSTOPCodonsIn5PrimeUTRSequence"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Transcripts with STOP codons in 5 prime UTR detected")
    
    
    current_time=time.time()
    runTrimmomaticToTrimOffAdapters(options,logger_proxy,logging_mutex)
    options.record_time["runTrimmomaticToTrimOffAdapters"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Trimmomatic run to trim off adapters completed")
    
    
    current_time=time.time()
    removeNFromFastq(options,logger_proxy,logging_mutex)
    options.record_time["removeNFromFastq"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Removal of leading and trailing Ns from fastq completed")
    
    
    current_time=time.time()
    alignReadsWithStarForTrimming(options,logger_proxy,logging_mutex)
    options.record_time["alignReadsWithStarForTrimming"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("STAR mapping completed")
    
    
    current_time=time.time()
    findReadsWithVectorSequenceAndTrim(options,logger_proxy,logging_mutex)
    options.record_time["findReadsWithVectorSequenceAndTrim"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Fusion read detection for all sequences are completed")
    
    
    current_time=time.time()
    reAlignReadsMappedToVector(options)
    options.record_time["reAlignReadsMappedToVector"]=str(convertToDateAndTime(int(time.time()-current_time)))
    
    current_time=time.time()
    prepareGenomeFilesForGenomeBrowser(options,logger_proxy,logging_mutex) # Problem in this function check later
    options.record_time["prepareGenomeFilesForGenomeBrowser"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Generation of files for viewing on genome browser completed")
    
    
    current_time=time.time()
    prepareTranscriptomeFiles(options,logger_proxy,logging_mutex)
    options.record_time["prepareTranscriptomeFiles"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Generation of transcriptomic files completed")
    
    
    current_time=time.time()
    runSalmonToGenerateCounts(options,logger_proxy,logging_mutex)
    options.record_time["runSalmonToGenerateCounts"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Generation of gene counts with Salmon completed")
    
    
    current_time=time.time()
    performEnrichmentAnalysis(options)
    options.record_time["performEnrichmentAnalysis"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Enrichment analysis with DESeq2 completed")
    
    
    current_time=time.time()
    generateReportFile(options,gene_info,transcripts_to_in_frame_STOP_codon_locations_in_5_prime_UTR_region)
    options.record_time["generateReportFile"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Generation of report file for all transcripts completed")
    
    
    current_time=time.time()
    createTranscriptomeFileForPrimerDesign(options,gene_info)
    options.record_time["createTranscriptomeFileForPrimerDesign"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Generation of file for primer design completed")
    
    
    current_time=time.time()
    generateRunReportFile(options)
    options.record_time["generateRunReportFile"]=str(convertToDateAndTime(int(time.time()-current_time)))
    with logging_mutex:
        logger_proxy.info("Generation of report file for run completed")
    
    
    with logging_mutex:
        logger_proxy.info("All functions were executed successfully")
    
    

if __name__ == "__main__":
    main()
